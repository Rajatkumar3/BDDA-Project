{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import * #Import spark types\n",
    "from pyspark.sql.functions import * #Import spark functions\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession #Import the spark session\n",
    "from pyspark import SparkContext #Create a spark context\n",
    "from pyspark.sql import SQLContext #Create an SQL context\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer #Used to tokenize the tweet data\n",
    "from pyspark.ml.feature import CountVectorizer #Used to make the data into vectors\n",
    "from pyspark.ml import Pipeline #Build a pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier #The chosen classifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator #Metrics\n",
    "\n",
    "conf = pyspark.SparkConf().setAll([('spark.executor.memory', '16g'), ('spark.executor.cores', '1'), ('spark.cores.max', '1'), ('spark.driver.memory','16g')])\n",
    "sc = SparkContext.getOrCreate(conf = conf) #Initialize the spark context\n",
    "sqlContext = SQLContext.getOrCreate(sc) #Create an SQL Context\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate() #Make a spark session\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark= SparkSession.builder.appName('Ans1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('Corona_NLP_train.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|            UserName|          ScreenName|            Location|             TweetAt|       OriginalTweet|Sentiment|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "|                3799|               48751|              London|          16-03-2020|@MeNyrbie @Phil_G...|  Neutral|\n",
      "|                3800|               48752|                  UK|          16-03-2020|advice Talk to yo...| Positive|\n",
      "|                3801|               48753|           Vagabonds|          16-03-2020|Coronavirus Austr...| Positive|\n",
      "|                3802|               48754|                null|          16-03-2020|My food stock is ...|     null|\n",
      "|              PLEASE|         don't panic| THERE WILL BE EN...|                null|                null|     null|\n",
      "|           Stay calm|          stay safe.|                null|                null|                null|     null|\n",
      "|#COVID19france #C...|            Positive|                null|                null|                null|     null|\n",
      "|                3803|               48755|                null|          16-03-2020|Me, ready to go a...|     null|\n",
      "|Not because I'm p...| but because my f...|          but please| don't panic. It ...|                null|     null|\n",
      "|#CoronavirusFranc...|  Extremely Negative|                null|                null|                null|     null|\n",
      "|                3804|               48756|ÜT: 36.319708,-82...|          16-03-2020|As news of the re...| Positive|\n",
      "|                3805|               48757|35.926541,-78.753267|          16-03-2020|\"Cashier at groce...| Positive|\n",
      "|                3806|               48758|             Austria|          16-03-2020|Was at the superm...|     null|\n",
      "|#toiletpapercrisi...|             Neutral|                null|                null|                null|     null|\n",
      "|                3807|               48759|     Atlanta, GA USA|          16-03-2020|Due to COVID-19 o...| Positive|\n",
      "|                3808|               48760|    BHAVNAGAR,GUJRAT|          16-03-2020|For corona preven...| Negative|\n",
      "|                3809|               48761|      Makati, Manila|          16-03-2020|All month there h...|  Neutral|\n",
      "|                3810|               48762|Pitt Meadows, BC,...|          16-03-2020|Due to the Covid-...|     null|\n",
      "|The wait time may...| particularly bee...|                null|                null|                null|     null|\n",
      "|We thank you for ...|  Extremely Positive|                null|                null|                null|     null|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+-------+-------------+---------+\n",
      "|UserName|ScreenName|Location|TweetAt|OriginalTweet|Sentiment|\n",
      "+--------+----------+--------+-------+-------------+---------+\n",
      "|       4|     12417|   33799|  26311|        26663|    39429|\n",
      "+--------+----------+--------+-------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show() #Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.na.drop(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+----------+--------------------+------------------+\n",
      "|UserName|ScreenName|            Location|   TweetAt|       OriginalTweet|         Sentiment|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+\n",
      "|    3799|     48751|              London|16-03-2020|@MeNyrbie @Phil_G...|           Neutral|\n",
      "|    3800|     48752|                  UK|16-03-2020|advice Talk to yo...|          Positive|\n",
      "|    3801|     48753|           Vagabonds|16-03-2020|Coronavirus Austr...|          Positive|\n",
      "|    3804|     48756|ÜT: 36.319708,-82...|16-03-2020|As news of the re...|          Positive|\n",
      "|    3805|     48757|35.926541,-78.753267|16-03-2020|\"Cashier at groce...|          Positive|\n",
      "|    3807|     48759|     Atlanta, GA USA|16-03-2020|Due to COVID-19 o...|          Positive|\n",
      "|    3808|     48760|    BHAVNAGAR,GUJRAT|16-03-2020|For corona preven...|          Negative|\n",
      "|    3809|     48761|      Makati, Manila|16-03-2020|All month there h...|           Neutral|\n",
      "|    3811|     48763|          Horningsea|16-03-2020|#horningsea is a ...|Extremely Positive|\n",
      "|    3818|     48770|          Denver, CO|16-03-2020|For those who are...|          Positive|\n",
      "|    3819|     48771|southampton soxx xxx|16-03-2020|with 100  nations...|Extremely Negative|\n",
      "|    3823|     48775|    Downstage centre|16-03-2020|@10DowningStreet ...|          Negative|\n",
      "|    3824|     48776|              London|16-03-2020|UK #consumer poll...|Extremely Positive|\n",
      "|    3825|     48777|      Ketchum, Idaho|16-03-2020|In preparation fo...|          Negative|\n",
      "|    3826|     48778| Everywhere You Are!|16-03-2020|This morning I te...|Extremely Negative|\n",
      "|    3834|     48786|             Sverige|16-03-2020|Went to the super...|           Neutral|\n",
      "|    3836|     48788|              Canada|16-03-2020|Worried about the...|          Positive|\n",
      "|    3838|     48790|       United States|16-03-2020|Now I can go to t...|          Positive|\n",
      "|    3841|     48793|             Houston|16-03-2020|CHECK VIDEO ?? ht...|Extremely Negative|\n",
      "|    3842|     48794|Vancouver, Britis...|16-03-2020|Breaking Story: O...|           Neutral|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "indexers = [StringIndexer(inputCol=\"Sentiment\", outputCol=\"Target\").fit(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=indexers)\n",
    "df_r = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentiment(label):\n",
    "    if label == \"Positive\" or label == \"Extremely Positive\":\n",
    "        return \"Positive\"\n",
    "    elif label == \"Negative\" or label == \"Extremely Negative\":\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringNumber = udf(lambda m: decode_sentiment(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=df.withColumn(\"target_Sentiment\", stringNumber(\"Sentiment\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list =[\"UserName\",\"ScreenName\",\"Location\",\"TweetAt\",\"Sentiment\"]\n",
    "data = tweets.select([column for column in tweets.columns if column not in drop_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|       OriginalTweet|target_Sentiment|\n",
      "+--------------------+----------------+\n",
      "|@MeNyrbie @Phil_G...|         Neutral|\n",
      "|advice Talk to yo...|        Positive|\n",
      "|Coronavirus Austr...|        Positive|\n",
      "|As news of the re...|        Positive|\n",
      "|\"Cashier at groce...|        Positive|\n",
      "|Due to COVID-19 o...|        Positive|\n",
      "|For corona preven...|        Negative|\n",
      "|All month there h...|         Neutral|\n",
      "|#horningsea is a ...|        Positive|\n",
      "|For those who are...|        Positive|\n",
      "|with 100  nations...|        Negative|\n",
      "|@10DowningStreet ...|        Negative|\n",
      "|UK #consumer poll...|        Positive|\n",
      "|In preparation fo...|        Negative|\n",
      "|This morning I te...|        Negative|\n",
      "|Went to the super...|         Neutral|\n",
      "|Worried about the...|        Positive|\n",
      "|Now I can go to t...|        Positive|\n",
      "|CHECK VIDEO ?? ht...|        Negative|\n",
      "|Breaking Story: O...|         Neutral|\n",
      "+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_set, val_set, test_set) = data.randomSplit([0.98, 0.01, 0.01], seed = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"OriginalTweet\", outputCol=\"words\")\n",
    "\n",
    "# Creating an instance of the TF-IDF\n",
    "hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n",
    "idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "\n",
    "# to convert string target to index target\n",
    "label_stringIdx = StringIndexer(inputCol = \"target_Sentiment\", outputCol = \"label\")\n",
    "\n",
    "# the complete pipeline: sequence of various stages\n",
    "pipeline = Pipeline(stages=[tokenizer, hashtf, idf, label_stringIdx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineFit = pipeline.fit(train_set)\n",
    "train_df = pipelineFit.transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+--------------------+--------------------+--------------------+-----+\n",
      "|       OriginalTweet|target_Sentiment|               words|                  tf|            features|label|\n",
      "+--------------------+----------------+--------------------+--------------------+--------------------+-----+\n",
      "|    Police office...|        Positive|[, , , , police, ...|(65536,[1434,1511...|(65536,[1434,1511...|  0.0|\n",
      "|   I told them th...|        Negative|[, , , i, told, t...|(65536,[1198,5660...|(65536,[1198,5660...|  1.0|\n",
      "|  A revised rail ...|        Positive|[, , a, revised, ...|(65536,[463,1032,...|(65536,[463,1032,...|  0.0|\n",
      "|  Add your favori...|        Positive|[, , add, your, f...|(65536,[19208,203...|(65536,[19208,203...|  0.0|\n",
      "|  COVID 19 UPDATE...|        Positive|[, , covid, 19, u...|(65536,[3856,4629...|(65536,[3856,4629...|  0.0|\n",
      "+--------------------+----------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#transform model with validataion datasets\n",
    "val_df = pipelineFit.transform(val_set)\n",
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression multiclass \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "LR = LogisticRegression(maxIter=100)\n",
    "model = LR.fit(train_df)\n",
    "predictions = model.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_data_sets = {\n",
    "    'OriginalTweet':[\n",
    "        \"i love to go shopping\",\n",
    "        'I hate the Master Chef US, its streaming this Friday on Fox #masterchef',\n",
    "        'i love cooking'\n",
    "    ]\n",
    "}\n",
    "\n",
    "test_result = pd.DataFrame(test_data_sets)\n",
    "\n",
    "test_result = sqlContext.createDataFrame(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(test_):\n",
    "    features = pipelineFit.transform(test_)\n",
    "    preds = model.transform(features)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|       0.0|\n",
      "|       1.0|\n",
      "|       0.0|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model_predict(test_result)\n",
    "pred.select('prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7335486778846153"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
